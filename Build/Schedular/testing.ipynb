{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86a7ec62-69c3-457e-a164-914617d4fbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKEND_URLS=\"http://10.1.7.221:8000,http://10.1.7.221:8001,http://10.1.7.221:8002\"\n",
    "CLOUD_SERVER_URL=\"http://10.1.7.221:8003\"\n",
    "CPU_THRESHOLD=5000\n",
    "MEM_THRESHOLD=5000\n",
    "CHECK_INTERVAL=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acaa8cd-1481-40b8-8f66-b3efae11f293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'current_requests': 0, 'cpu_percent': 4.9, 'memory_percent': 47.5, 'net_bytes_sent': 54907, 'net_bytes_recv': 24849, 'num_threads': 27}, {'current_requests': 0, 'cpu_percent': 0.0, 'memory_percent': 47.5, 'net_bytes_sent': 54907, 'net_bytes_recv': 24849, 'num_threads': 27}, {'current_requests': 0, 'cpu_percent': 0.0, 'memory_percent': 47.6, 'net_bytes_sent': 54907, 'net_bytes_recv': 24849, 'num_threads': 27}, {'current_requests': 0, 'cpu_percent': 0.0, 'memory_percent': 47.6, 'net_bytes_sent': 54907, 'net_bytes_recv': 24849, 'num_threads': 27}, {'current_requests': 0, 'cpu_percent': 1.2, 'memory_percent': 47.6, 'net_bytes_sent': 54907, 'net_bytes_recv': 24849, 'num_threads': 27}, {'current_requests': 0, 'cpu_percent': 0.0, 'memory_percent': 47.6, 'net_bytes_sent': 54907, 'net_bytes_recv': 24849, 'num_threads': 27}, {'current_requests': 0, 'cpu_percent': 1.2, 'memory_percent': 47.6, 'net_bytes_sent': 54907, 'net_bytes_recv': 24849, 'num_threads': 27}, {'current_requests': 0, 'cpu_percent': 0.0, 'memory_percent': 47.6, 'net_bytes_sent': 54907, 'net_bytes_recv': 24849, 'num_threads': 27}, {'current_requests': 0, 'cpu_percent': 1.2, 'memory_percent': 47.6, 'net_bytes_sent': 54907, 'net_bytes_recv': 24849, 'num_threads': 27}, {'current_requests': 0, 'cpu_percent': 0.0, 'memory_percent': 47.6, 'net_bytes_sent': 54907, 'net_bytes_recv': 24849, 'num_threads': 27}]\n",
      "[[0.         1.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.         0.         0.        ]\n",
      " [0.         0.24489796 1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.         0.         0.        ]\n",
      " [0.         0.24489796 1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.         0.         0.        ]\n",
      " [0.         0.24489796 1.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.         0.         0.        ]]\n",
      "[[[0.         1.         0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.        ]\n",
      "  [0.         0.         1.         0.         0.         0.        ]\n",
      "  [0.         0.         1.         0.         0.         0.        ]\n",
      "  [0.         0.24489796 1.         0.         0.         0.        ]\n",
      "  [0.         0.         1.         0.         0.         0.        ]\n",
      "  [0.         0.24489796 1.         0.         0.         0.        ]\n",
      "  [0.         0.         1.         0.         0.         0.        ]\n",
      "  [0.         0.24489796 1.         0.         0.         0.        ]\n",
      "  [0.         0.         1.         0.         0.         0.        ]]]\n",
      "[http://10.1.7.221:8000] CPU: 1.0095, MEM: 0.1855, Score: 1.1950\n",
      "[Health Check] Best backend selected: http://10.1.7.221:8000 (Score: 1.1950)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import requests\n",
    "from tensorflow.keras.losses import mse\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "BACKEND_URLS = BACKEND_URLS.split(\",\")\n",
    "CLOUD_SERVER_URL = CLOUD_SERVER_URL\n",
    "MEM_THRESHOLD = float(MEM_THRESHOLD)\n",
    "CPU_THRESHOLD = float(CPU_THRESHOLD)\n",
    "CHECK_INTERVAL = float(CHECK_INTERVAL)\n",
    "\n",
    "# Load LSTM model\n",
    "model = tf.keras.models.load_model('lstm_model.h5', compile=False)\n",
    "\n",
    "# Global variable to track best backend safely\n",
    "best_backend_url = None\n",
    "\n",
    "def periodic_health_check():\n",
    "    global best_backend_url\n",
    "\n",
    "    best_node = None\n",
    "    best_score = float('inf')  # lower combined CPU+MEM is better\n",
    "\n",
    "    for backend_url in BACKEND_URLS:\n",
    "        try:\n",
    "            metrics_response = requests.get(f\"{backend_url}/metrics\", timeout=5)\n",
    "            if metrics_response.status_code == 200:\n",
    "                data = metrics_response.json()\n",
    "                instances_raw = data.get(\"instances\")\n",
    "                # Convert list of dicts into (10, 6) array\n",
    "                print(instances_raw)\n",
    "                last_10_instances = np.array([\n",
    "                    [\n",
    "                        inst[\"current_requests\"],\n",
    "                        inst[\"cpu_percent\"],\n",
    "                        inst[\"memory_percent\"],\n",
    "                        inst[\"net_bytes_sent\"],\n",
    "                        inst[\"net_bytes_recv\"],\n",
    "                        inst[\"num_threads\"]\n",
    "                    ]\n",
    "                    for inst in instances_raw\n",
    "                ])\n",
    "                last_10_instances = scaler.fit_transform(last_10_instances) \n",
    "                print(last_10_instances)\n",
    "                if last_10_instances.shape == (10, 6):\n",
    "                    input_data = last_10_instances.reshape((1, 10, 6))\n",
    "                    print(input_data)\n",
    "                    prediction = model.predict(input_data, verbose=0)\n",
    "                    predicted_cpu = prediction[0][0]\n",
    "                    predicted_mem = prediction[0][1]\n",
    "                    combined_score = predicted_cpu + predicted_mem\n",
    "\n",
    "                    print(f\"[{backend_url}] CPU: {predicted_cpu:.4f}, MEM: {predicted_mem:.4f}, Score: {combined_score:.4f}\")\n",
    "\n",
    "                    if (predicted_cpu < CPU_THRESHOLD and\n",
    "                        predicted_mem < MEM_THRESHOLD and\n",
    "                        combined_score < best_score):\n",
    "                        best_node = backend_url\n",
    "                        best_score = combined_score\n",
    "                else:\n",
    "                    print(f\"[{backend_url}] Invalid shape after extraction: {last_10_instances.shape}\")\n",
    "            else:\n",
    "                print(f\"[{backend_url}] Failed to get metrics (status {metrics_response.status_code})\")\n",
    "        except Exception as e:\n",
    "            print(f\"[{backend_url}] Error: {e}\")\n",
    "        break\n",
    "        \n",
    "\n",
    "    best_backend_url = best_node\n",
    "\n",
    "    if best_node:\n",
    "        print(f\"[Health Check] Best backend selected: {best_node} (Score: {best_score:.4f})\")\n",
    "    else:\n",
    "        print(\"[Health Check] No backend under threshold; will use cloud fallback\")\n",
    "periodic_health_check()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac2428e-543a-41d9-ba03-18c8f5c67b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(BACKEND_URLS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d2a2d0-b344-4789-ae3a-15ef6beecb38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7b43a2f-2bad-459b-8cea-12faef55caec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
